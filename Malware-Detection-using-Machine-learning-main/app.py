import os
import pickle
from flask import Flask, request, render_template, jsonify
from sklearn.feature_extraction.text import TfidfVectorizer
from sanitization import sanitization  # Import the function

app = Flask(__name__)

# Load the pre-trained model and vectorizer
model_path = "Classifier/pickel_model.pkl"
vectorizer_path = "Classifier/pickel_vector.pkl"

with open(model_path, 'rb') as model_file:
    model = pickle.load(model_file)

with open(vectorizer_path, 'rb') as vectorizer_file:
    vectorizer = pickle.load(vectorizer_file)

# Whitelist of safe URLs
whitelist = ['hackthebox.eu', 'root-me.org', 'gmail.com']

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/scan_url', methods=['POST'])
def scan_url():
    url = request.form.get('url')
    
    # Check if the URL is in the whitelist
    if url in whitelist:
        result = "good"
    else:
        # Preprocess and vectorize the URL
        url_vector = vectorizer.transform([url])
        prediction = model.predict(url_vector)
        result = "bad" if prediction[0] == "bad" else "good"
    
    return jsonify({"result": result})

if __name__ == "__main__":
    app.run(debug=True)
